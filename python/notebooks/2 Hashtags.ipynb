{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "from utils.paths import make_dirs, QUARTERS_DICT, HASHTAGS_PER_USER_DIR, HASHTAG_FREQUENCY_DIR, HASHTAG_FREQUENCY_DIR_ALL, HASHTAG_TOP_DIR\n",
    "from utils.utils import load_dataframes, load_dataframe, write_dict_to_csv, write_list_to_csv, write_df_to_csv\n",
    "import pandas as pd\n",
    "import os\n",
    "from nltk.probability import FreqDist\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "make_dirs()\n",
    "\n",
    "min_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_user(df):\n",
    "    df = df.groupby('owner_id').agg(\n",
    "        hashtags=pd.NamedAgg(column='hashtags', aggfunc='sum'), \n",
    "        post_count=pd.NamedAgg(column='shortcode', aggfunc='count'),\n",
    "    )\n",
    "    df = df.sort_values(by=['post_count'], ascending=False)\n",
    "    df['hashtags'] = df['hashtags'].apply(lambda x: list(set(x)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hashtag_frequency(df):\n",
    "    hashtags = list(df['hashtags'])\n",
    "    flat_list = [item.lower() for sublist in hashtags for item in sublist]    \n",
    "    fdist = FreqDist(flat_list)\n",
    "    return fdist.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count hashtags in every district\n",
    "- Group hashtags by user in order to give every user one \"vote\" per hashtag\n",
    "- count absolute and relative amount \n",
    "- drop hashtags that are mentioned by less than [min_count] people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = QUARTERS_DICT()\n",
    "for quarter in dict:\n",
    "    print('>> now processing', quarter)\n",
    "    df = dict[quarter]\n",
    "    df = group_by_user(df)\n",
    "    write_df_to_csv(df, quarter, HASHTAGS_PER_USER_DIR)\n",
    "    fdist = count_hashtag_frequency(df)\n",
    "    df = pd.DataFrame(fdist, columns=['hashtag', 'count'])\n",
    "    df.drop(df[df['count'] < min_count].index, inplace = True)\n",
    "    count_quarter = df.iloc[0]['count']\n",
    "    df['relative_amount'] = df['count'] / count_quarter\n",
    "    write_df_to_csv(df, quarter, HASHTAG_FREQUENCY_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count hashtags in the whole city\n",
    "- Same as above, but for posts downloaded from all districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "dict = QUARTERS_DICT()\n",
    "for quarter in dict:\n",
    "    df = df.append(dict[quarter])\n",
    "    print('>> now processing', quarter)\n",
    "\n",
    "\n",
    "df = df.drop_duplicates(subset='post_url', keep=\"first\")\n",
    "df = group_by_user(df)\n",
    "user_count = len(df)\n",
    "\n",
    "fdist = count_hashtag_frequency(df)\n",
    "df = pd.DataFrame(fdist, columns=['hashtag', 'count'])\n",
    "df.drop(df[df['count'] < min_count].index, inplace = True)\n",
    "df['relative_amount'] = df['count'] / user_count\n",
    "\n",
    "write_df_to_csv(df,'count_all_quarters', HASHTAG_FREQUENCY_DIR_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate uniqueness and rank of hashtags for every district\n",
    "- uniqueness: ratio between relative amount of a hashtag in a district and relative amount in all districts\n",
    "- rank: total amount * uniqueness^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniqueness(dfs, df_all, out_dir):\n",
    "    idx = 1\n",
    "\n",
    "    for quarter in dfs:\n",
    "        print ('file no:', idx)\n",
    "        idx += 1\n",
    "        print ('>> now processing:', quarter)\n",
    "        df = dfs[quarter]\n",
    "        df.set_index('hashtag')\n",
    "\n",
    "        df = df.join(df_all.set_index('hashtag'), on='hashtag', lsuffix='_quarter', rsuffix='_city')\n",
    "        df['uniqueness'] = df['relative_amount_quarter'] / df['relative_amount_city']\n",
    "        df['rank'] = df['count_quarter'] * df['uniqueness'] * df['uniqueness']\n",
    "        df.sort_values(by=['rank'], ascending=False, inplace=True)\n",
    "        write_df_to_csv(df, quarter, out_dir)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = load_dataframes(HASHTAG_FREQUENCY_DIR)\n",
    "df_all = load_dataframe(HASHTAG_FREQUENCY_DIR_ALL, 'count_all_quarters')\n",
    "\n",
    "get_uniqueness(dfs, df_all, HASHTAG_TOP_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
