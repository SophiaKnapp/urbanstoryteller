{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "from utils.paths import make_dirs, QUARTERS_DICT, PUBLIC_SPACES_DICT, QUARTERS_ALL_POSTS, HASHTAGS_PER_USER_DIR, HASHTAG_FREQUENCY_DIR, CONNECTED_COMPONENTS_DIR, CONNECTED_COMPONENTS_PUBLIC_SPACES_DIR, HASHTAG_FREQUENCY_PUBLIC_SPACES_DIR, HASHTAGS_PER_USER_PUBLIC_SPACES_DIR\n",
    "from utils.utils import load_dataframes, load_dataframe, write_df_to_csv, write_list_to_csv\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from network.network import generate_graph, draw_graph\n",
    "from frequency.frequency import count_hashtag_frequency, group_by_user\n",
    "import os\n",
    "\n",
    "make_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort hashtags by user, so every person only gets \"one vote\" per hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> now loading: allach\n",
      ">> now loading: altperlach\n",
      ">> now loading: altstadt\n",
      ">> now loading: amhart\n",
      ">> now loading: arabellapark\n",
      ">> now loading: au\n",
      ">> now loading: aubing\n",
      ">> now loading: bergamlaim\n",
      ">> now loading: bogenhausen\n",
      ">> now loading: borstei\n",
      ">> now loading: daglfing\n",
      ">> now loading: denning\n",
      ">> now loading: fasanerie\n",
      ">> now loading: fasangarten\n",
      ">> now loading: feldmoching\n",
      ">> now loading: forstenried\n",
      ">> now loading: freiham\n",
      ">> now loading: freimann\n",
      ">> now loading: fröttmaning\n",
      ">> now loading: fürstenried\n",
      ">> now loading: giesing\n",
      ">> now loading: hadern\n",
      ">> now loading: haidhausen\n",
      ">> now loading: harlaching\n",
      ">> now loading: harras\n",
      ">> now loading: harthof\n",
      ">> now loading: hasenbergl\n",
      ">> now loading: hellabrunn\n",
      ">> now loading: herzogpark\n",
      ">> now loading: isarvorstadt\n",
      ">> now loading: johanneskirchen\n",
      ">> now loading: kieferngarten\n",
      ">> now loading: kirchtrudering\n",
      ">> now loading: laim\n",
      ">> now loading: lehel\n",
      ">> now loading: lerchenau\n",
      ">> now loading: lochhausen\n",
      ">> now loading: ludwigsvorstadt\n",
      ">> now loading: maxvorstadt\n",
      ">> now loading: messestadtriem\n",
      ">> now loading: milbertshofen\n",
      ">> now loading: mittersendling\n",
      ">> now loading: moosach\n",
      ">> now loading: neuaubing\n",
      ">> now loading: neubiberg\n",
      ">> now loading: neuhausen\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6c/_dzq3mkj1pn46mx5cn0zmsg00000gn/T/ipykernel_34916/984422685.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQUARTERS_DICT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquarter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>> now processing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquarter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquarter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_by_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/instagrammining/utils/paths.py\u001b[0m in \u001b[0;36mQUARTERS_DICT\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mquarter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpotatoes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'>> now loading:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquarter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mquarters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquarter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQUARTER_CLEANED_RESULTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquarter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mquarters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/instagrammining/utils/paths.py\u001b[0m in \u001b[0;36mQUARTER_CLEANED_RESULTS\u001b[0;34m(quarter)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mQUARTER_CLEANED_RESULTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquarter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPOTATOES_CLEANED_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquarter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mread_result_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mQUARTERS_DICT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/instagrammining/utils/utils.py\u001b[0m in \u001b[0;36mread_result_csv\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_result_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m'hashtags'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hashtags'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hashtags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_literals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m     \"\"\"\n\u001b[1;32m   1567\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dict = QUARTERS_DICT()\n",
    "for quarter in dict:\n",
    "    print('>> now processing', quarter)\n",
    "    df = dict[quarter]\n",
    "    df = group_by_user(df)\n",
    "    write_df_to_csv(df, quarter, HASHTAGS_PER_USER_DIR)\n",
    "    fdist = count_hashtag_frequency(df)\n",
    "    write_list_to_csv(fdist, quarter, HASHTAG_FREQUENCY_DIR, columns=['hashtag', 'count'])\n",
    "\n",
    "# copierd this to 2 rank!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and draw network, separately per quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> now loading: allach\n",
      ">> now loading: altperlach\n",
      ">> now loading: altstadt\n",
      ">> now loading: amhart\n",
      ">> now loading: arabellapark\n",
      ">> now loading: allach\n",
      ">> now loading: altperlach\n",
      ">> now loading: altstadt\n",
      ">> now loading: amhart\n",
      ">> now loading: arabellapark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pandas/core/frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allach\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6c/_dzq3mkj1pn46mx5cn0zmsg00000gn/T/ipykernel_34916/4161644932.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquarter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashtags_per_user_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mforbidden_hashtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mquarter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'münchen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'munich'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'muc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bayern'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bavaria'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'muenchen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'minga'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'germany'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deutschland'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquarter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashtags_per_user_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquarter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_node_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_treshold_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_treshold_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_edge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforbidden_hashtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# (df_frequencies, df_users, n_nodes, min_edge_weight, min_node_weight, min_degree, noise_treshold_1, noise_treshold_2, forbidden_hashtags=[]):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/instagrammining/hashtags/network/network.py\u001b[0m in \u001b[0;36mgenerate_graph\u001b[0;34m(df_frequencies, df_users, n_nodes, min_edge_weight, min_node_weight, min_degree, noise_treshold_1, noise_treshold_2, forbidden_hashtags)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcount_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mcount_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0medge_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'count'"
     ]
    }
   ],
   "source": [
    "hashtags_per_user_dict = load_dataframes(HASHTAGS_PER_USER_DIR,5)\n",
    "frequencies = load_dataframes(HASHTAG_FREQUENCY_DIR,5)\n",
    "n_nodes = 1000\n",
    "noise_treshold_1 = 10\n",
    "noise_treshold_2 = 5\n",
    "max_node_size = 1500\n",
    "max_font_size = 12\n",
    "min_edge_weight = 0\n",
    "min_node_weight = 10\n",
    "min_degree = 2\n",
    "\n",
    "for quarter in hashtags_per_user_dict:\n",
    "    forbidden_hashtags = [quarter, 'münchen', 'munich', 'muc', 'mu', 'bayern', 'bavaria', 'muenchen', 'minga', 'germany', 'deutschland']\n",
    "    G = generate_graph(frequencies[quarter], hashtags_per_user_dict[quarter], n_nodes, min_node_weight, min_degree, noise_treshold_1, noise_treshold_2, min_edge_weight, forbidden_hashtags)\n",
    "\n",
    "    # (df_frequencies, df_users, n_nodes, min_edge_weight, min_node_weight, min_degree, noise_treshold_1, noise_treshold_2, forbidden_hashtags=[]):\n",
    "    # draw_graph(G, max_node_size, max_font_size,quarter,CONNECTED_COMPONENTS_DIR)\n",
    "    \n",
    "    print(quarter)\n",
    "    print(nx.number_connected_components(G))\n",
    "    # components = nx.connected_components(G)\n",
    "    # for c in sorted(nx.connected_components(G), key=len, reverse=True):\n",
    "    #     print(c)\n",
    "    final_list = [list(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "    write_list_to_csv(final_list, quarter, CONNECTED_COMPONENTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count frequency for all quarters - one vote per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> now loading: allach\n",
      ">> now loading: altperlach\n",
      ">> now loading: altstadtlocation\n",
      ">> now loading: altstadtmünchen\n",
      ">> now loading: amhart\n",
      ">> now loading: arabellapark\n",
      ">> now loading: aubing\n",
      ">> now loading: aulocation\n",
      ">> now loading: aumünchen\n",
      ">> now loading: bergamlaim\n",
      ">> now loading: bogenhausen\n",
      ">> now loading: borstei\n",
      ">> now loading: daglfing\n",
      ">> now loading: denning\n",
      ">> now loading: fasanerie\n",
      ">> now loading: fasangarten\n",
      ">> now loading: feldmoching\n",
      ">> now loading: forstenried\n",
      ">> now loading: freiham\n",
      ">> now loading: freimann\n",
      ">> now loading: fröttmaning\n",
      ">> now loading: fürstenried\n",
      ">> now loading: giesing\n",
      ">> now loading: hadern\n",
      ">> now loading: haidhausen\n",
      ">> now loading: harlaching\n",
      ">> now loading: harras\n",
      ">> now loading: harthof\n",
      ">> now loading: hasenbergl\n",
      ">> now loading: hellabrunn\n",
      ">> now loading: herzogpark\n",
      ">> now loading: isarvorstadt\n",
      ">> now loading: johanneskirchen\n",
      ">> now loading: kieferngarten\n",
      ">> now loading: kirchtrudering\n",
      ">> now loading: laim\n",
      ">> now loading: lehel\n",
      ">> now loading: lerchenau\n",
      ">> now loading: lochhausen\n",
      ">> now loading: ludwigsvorstadt\n",
      ">> now loading: maxvorstadt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophiaknapp/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3437: DtypeWarning: Columns (0,4,5,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> now loading: messestadtriem\n",
      ">> now loading: milbertshofen\n",
      ">> now loading: mittersendling\n",
      ">> now loading: moosach\n",
      ">> now loading: neuaubing\n",
      ">> now loading: neubiberg\n",
      ">> now loading: neuhausen\n",
      ">> now loading: neuperlach\n",
      ">> now loading: nymphenburg\n",
      ">> now loading: oberföhring\n",
      ">> now loading: obermenzing\n",
      ">> now loading: obersendling\n",
      ">> now loading: olympiadorf\n",
      ">> now loading: pasing\n",
      ">> now loading: ramersdorf\n",
      ">> now loading: riem\n",
      ">> now loading: schwabing\n",
      ">> now loading: sendling\n",
      ">> now loading: solln\n",
      ">> now loading: studentenstadt\n",
      ">> now loading: thalkirchen\n",
      ">> now loading: trudering\n",
      ">> now loading: untermenzing\n",
      ">> now loading: waldtrudering\n",
      ">> now loading: werksviertel\n",
      ">> now loading: westend\n",
      ">> now loading: westkreuz\n",
      ">> now loading: zamdorf\n",
      "       owner_id    shortcode  \\\n",
      "0  4.747641e+10  CcPcLs5INO8   \n",
      "1  4.747641e+10  CcPbjh5oLtE   \n",
      "2  4.747641e+10  CcPar48o0gw   \n",
      "3  4.621776e+10  CcPULlwF6g3   \n",
      "4  4.745500e+10  CcN7BQ1qQKC   \n",
      "5  7.326886e+09  CcN4XOJIjy_   \n",
      "6  8.480212e+09  CcN3j7Cq9mz   \n",
      "7  4.957393e+10  CcLhyP2ILEY   \n",
      "8  1.230372e+10  CcLC5taILsG   \n",
      "9  4.501958e+10  CcKa3c0MBWr   \n",
      "\n",
      "                                            hashtags  \n",
      "0  [secondhand, secondchance, gutfürdieumwelt, mu...  \n",
      "1  [sustainable, zugutzumwegwerfen, secondhandsho...  \n",
      "2  [sustainable, zugutzumwegwerfen, secondhandsho...  \n",
      "3  [gin, ginliebhaber, ginliebe, premiumgin, prem...  \n",
      "4  [weineltbau, weineltteam, beton, fertigteile, ...  \n",
      "5  [schuhmair, schuhmairallach, schuhmaircafee, a...  \n",
      "6  [fahrschule, fahrlehrer, autofahrt, fahrschüle...  \n",
      "7  [münchen, allach, untermenzing, demenz, gesund...  \n",
      "8  [allguth, rezension, foodtanke, allguthfood, a...  \n",
      "9  [bullterrier, beifahrerin, hundeleben, bullter...  \n",
      "907202\n",
      "793870\n",
      "       owner_id    shortcode  \\\n",
      "0  4.747641e+10  CcPcLs5INO8   \n",
      "1  4.747641e+10  CcPbjh5oLtE   \n",
      "2  4.747641e+10  CcPar48o0gw   \n",
      "3  4.621776e+10  CcPULlwF6g3   \n",
      "4  4.745500e+10  CcN7BQ1qQKC   \n",
      "\n",
      "                                            hashtags  \n",
      "0  [secondhand, secondchance, gutfürdieumwelt, mu...  \n",
      "1  [sustainable, zugutzumwegwerfen, secondhandsho...  \n",
      "2  [sustainable, zugutzumwegwerfen, secondhandsho...  \n",
      "3  [gin, ginliebhaber, ginliebe, premiumgin, prem...  \n",
      "4  [weineltbau, weineltteam, beton, fertigteile, ...  \n",
      "3961316\n"
     ]
    }
   ],
   "source": [
    "df = QUARTERS_ALL_POSTS()\n",
    "print(df[:5])\n",
    "df = group_by_user(df)\n",
    "write_df_to_csv(df, 'city', HASHTAGS_PER_USER_DIR)\n",
    "fdist = count_hashtag_frequency(df)\n",
    "write_list_to_csv(fdist, 'city', HASHTAG_FREQUENCY_DIR, columns=['hashtag', 'count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find connected components - specify place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 100\n",
    "noise_treshold_1 = 5\n",
    "noise_treshold_2 = 0\n",
    "max_node_size = 1500\n",
    "max_font_size = 12\n",
    "min_edge_weight = 2\n",
    "\n",
    "# quarter = 'city'\n",
    "quarter = 'neuperlach'\n",
    "\n",
    "df_frequency = load_dataframe(HASHTAG_FREQUENCY_DIR, quarter)\n",
    "df_user = load_dataframe(HASHTAGS_PER_USER_DIR, quarter)\n",
    "\n",
    "file_name = quarter + '_' + str(n_nodes) + 'nodes_' + str(noise_treshold_1) + '_' + str(noise_treshold_2)\n",
    "\n",
    "# forbidden_hashtags = [quarter, 'münchen', 'munich', 'muc', 'mu', 'bayern', 'bavaria', 'muenchen', 'minga', 'germany', 'deutschland']\n",
    "G = generate_graph(df_frequency, df_user, n_nodes, min_edge_weight, noise_treshold_1, noise_treshold_2, [quarter])\n",
    "print(nx.number_connected_components(G))\n",
    "final_list = [list(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "write_list_to_csv(final_list, file_name, CONNECTED_COMPONENTS_DIR)\n",
    "\n",
    "draw_graph(G, max_node_size, max_font_size,file_name,CONNECTED_COMPONENTS_DIR)\n",
    "\n",
    "# draw subgraphs\n",
    "# subgraphs_dir = os.path.join(CONNECTED_COMPONENTS_DIR, file_name)\n",
    "# make_dirs([subgraphs_dir])\n",
    "# for index, c in enumerate(G.subgraph(c).copy() for c in nx.connected_components(G)):\n",
    "#     draw_graph(c, max_node_size, max_font_size,quarter+'_'+str(index),subgraphs_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find connected components - specific quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3820597440cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mquarter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ostparkmünchen'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHASHTAG_FREQUENCY_PUBLIC_SPACES_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquarter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdf_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHASHTAGS_PER_USER_PUBLIC_SPACES_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquarter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "n_nodes = 300\n",
    "noise_treshold_1 = 25\n",
    "noise_treshold_2 = 5\n",
    "# noise_treshold_1 = 0\n",
    "# noise_treshold_2 = 0\n",
    "max_node_size = 800\n",
    "max_font_size = 8\n",
    "min_edge_weight = 2\n",
    "min_node_weight = 2\n",
    "min_degree = 2\n",
    "\n",
    "# quarter = 'city'\n",
    "# quarter = 'neuperlach'\n",
    "quarter = 'ostparkmünchen'\n",
    "\n",
    "df_frequency = load_dataframe(HASHTAG_FREQUENCY_PUBLIC_SPACES_DIR, quarter)\n",
    "df_user = load_dataframe(HASHTAGS_PER_USER_PUBLIC_SPACES_DIR, quarter)\n",
    "\n",
    "\n",
    "# df_frequency = load_dataframe(HASHTAG_FREQUENCY_DIR, quarter)\n",
    "# df_user = load_dataframe(HASHTAGS_PER_USER_DIR, quarter)\n",
    "\n",
    "\n",
    "file_name = quarter + '_' + str(n_nodes) + 'nodes_' + str(noise_treshold_1) + '_' + str(noise_treshold_2)\n",
    "forbidden_hashtags = [quarter, 'münchen', 'munich', 'muc', 'mu', 'bayern', 'bavaria', 'muenchen', 'minga', 'germany', 'deutschland', '089']\n",
    "G = generate_graph(df_frequency, df_user, n_nodes, min_edge_weight, min_node_weight, min_degree, noise_treshold_1, noise_treshold_2, forbidden_hashtags)\n",
    "print(nx.number_connected_components(G))\n",
    "final_list = [list(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "\n",
    "# write_list_to_csv(final_list, file_name, CONNECTED_COMPONENTS_DIR)\n",
    "\n",
    "# draw_graph(G, max_node_size, max_font_size,file_name,CONNECTED_COMPONENTS_DIR)\n",
    "draw_graph(G, max_node_size, max_font_size,file_name,CONNECTED_COMPONENTS_PUBLIC_SPACES_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
