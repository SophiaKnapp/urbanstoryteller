{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sophiaknapp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sophiaknapp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "from utils.paths import QUARTERS_DICT, PUBLIC_SPACES_DICT, QUARTERS_ALL_POSTS, HASHTAGS_PER_USER_DIR, HASHTAG_FREQUENCY_DIR, CONNECTED_COMPONENTS_DIR, CONNECTED_COMPONENTS_PUBLIC_SPACES_DIR, HASHTAG_FREQUENCY_PUBLIC_SPACES_DIR, HASHTAGS_PER_USER_PUBLIC_SPACES_DIR, USERS_GRAPHS_DIR\n",
    "from utils.utils import make_dirs, load_dataframes, load_dataframe, write_df_to_csv, write_list_to_csv\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from network.network import generate_graph_users, draw_graph_users\n",
    "from frequency.frequency import count_hashtag_frequency, group_by_user\n",
    "import os\n",
    "\n",
    "make_dirs([HASHTAGS_PER_USER_DIR, HASHTAG_FREQUENCY_DIR, CONNECTED_COMPONENTS_DIR, CONNECTED_COMPONENTS_PUBLIC_SPACES_DIR, HASHTAG_FREQUENCY_PUBLIC_SPACES_DIR, HASHTAGS_PER_USER_PUBLIC_SPACES_DIR, USERS_GRAPHS_DIR])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> now loading: neuperlach\n",
      ">> now loading: neuperlach\n",
      "1\n",
      "NEW COMPONENT\n",
      "0\n",
      "2008\n"
     ]
    }
   ],
   "source": [
    "quarter = 'neuperlach'\n",
    "df = load_dataframe(HASHTAGS_PER_USER_DIR, quarter)\n",
    "df_frequency = load_dataframe(HASHTAG_FREQUENCY_DIR, quarter)\n",
    "\n",
    "n_nodes = 200\n",
    "min_edge_weight = 2\n",
    "noise_treshold_1 = 0\n",
    "noise_treshold_2 = 0\n",
    "max_font_size = 12\n",
    "min_degree = 2\n",
    "\n",
    "forbidden_hashtags = [quarter, 'm√ºnchen', 'munich', 'muc', 'mu', 'bayern', 'bavaria', 'muenchen', 'minga', 'germany', 'deutschland', '089']\n",
    "G = generate_graph_users(df, df_frequency, n_nodes, min_edge_weight, min_degree, noise_treshold_1, noise_treshold_2, forbidden_hashtags)\n",
    "\n",
    "# draw_graph_users(G, max_font_size, quarter, USERS_GRAPHS_DIR)\n",
    "\n",
    "print(nx.number_connected_components(G))\n",
    "final_list = [list(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "\n",
    "\n",
    "for index, c in enumerate(G.subgraph(c).copy() for c in nx.connected_components(G)):\n",
    "    # draw_graph(c, max_node_size, max_font_size,quarter+'_'+str(index),subgraphs_dir)\n",
    "    print(\"NEW COMPONENT\")\n",
    "    print(index)\n",
    "    hashtags = nx.get_edge_attributes(c, 'hashtags')\n",
    "    print(len(hashtags))\n",
    "\n",
    "# write_list_to_csv(final_list, file_name, CONNECTED_COMPONENTS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b29fe384102e255f393b184bf00e11949dbcca5ad9620b64cfbd1134dc28a425"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
